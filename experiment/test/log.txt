HNCT(
  (fea_conv): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B2): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B3): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B4): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (c): Sequential(
    (0): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(50, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
HNCT(
  (fea_conv): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B2): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B3): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B4): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (c): Sequential(
    (0): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(50, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
HNCT(
  (fea_conv): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B2): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B3): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B4): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (c): Sequential(
    (0): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(50, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
HNCT(
  (fea_conv): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B2): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B3): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B4): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (c): Sequential(
    (0): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(50, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0816]	72.1+19.7s
[3200/16000]	[L1: 0.0637]	65.9+0.2s
[4800/16000]	[L1: 0.0555]	65.4+0.2s
[6400/16000]	[L1: 0.0508]	65.6+0.2s
[8000/16000]	[L1: 0.0475]	65.8+0.2s
[9600/16000]	[L1: 0.0452]	64.3+0.2s
[11200/16000]	[L1: 0.0434]	59.8+0.2s
[12800/16000]	[L1: 0.0421]	60.4+0.2s
[14400/16000]	[L1: 0.0410]	61.0+0.2s
[16000/16000]	[L1: 0.0401]	61.9+0.2s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B2): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B3): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B4): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (c): Sequential(
    (0): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(50, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0854]	61.7+3.8s
[3200/16000]	[L1: 0.0658]	61.7+0.3s
[4800/16000]	[L1: 0.0573]	62.1+0.3s
[6400/16000]	[L1: 0.0520]	61.0+0.4s
[8000/16000]	[L1: 0.0484]	62.2+0.3s
[9600/16000]	[L1: 0.0460]	62.3+0.3s
[11200/16000]	[L1: 0.0440]	62.0+0.3s
[12800/16000]	[L1: 0.0426]	61.9+0.4s
[14400/16000]	[L1: 0.0415]	61.4+0.4s
[16000/16000]	[L1: 0.0405]	61.6+0.2s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B2): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B3): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B4): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (c): Sequential(
    (0): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(50, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0935]	60.7+2.6s
[3200/16000]	[L1: 0.0709]	61.0+0.1s
[4800/16000]	[L1: 0.0608]	61.3+0.1s
[6400/16000]	[L1: 0.0550]	61.2+0.1s
[8000/16000]	[L1: 0.0512]	61.2+0.0s
[9600/16000]	[L1: 0.0483]	61.2+0.0s
[11200/16000]	[L1: 0.0462]	61.1+0.2s
[12800/16000]	[L1: 0.0446]	61.2+0.1s
[14400/16000]	[L1: 0.0434]	61.2+0.1s
[16000/16000]	[L1: 0.0423]	61.7+0.2s

Evaluation:
HNCT(
  (fea_conv): Conv2d(3, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (B1): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B2): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B3): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (B4): HBCT(
    (c1_r): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (esa): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (esa2): ESA(
      (conv1): Conv2d(50, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_f): Conv2d(12, 12, kernel_size=(1, 1), stride=(1, 1))
      (conv_max): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(2, 2))
      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv3_): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv4): Conv2d(12, 50, kernel_size=(1, 1), stride=(1, 1))
      (sigmoid): Sigmoid()
      (relu): ReLU(inplace=True)
    )
    (swinT): SwinT(
      (transformer_body): Sequential(
        (0): BasicLayer(
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                (qkv): Linear(in_features=50, out_features=150, bias=True)
                (proj): Linear(in_features=50, out_features=50, bias=True)
                (softmax): Softmax(dim=-1)
              )
              (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=50, out_features=100, bias=True)
                (act): GELU(approximate=none)
                (fc2): Linear(in_features=100, out_features=50, bias=True)
              )
            )
          )
          (patch_embed): PatchEmbed(
            (norm): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
          )
          (patch_unembed): PatchUnEmbed()
        )
      )
    )
  )
  (c): Sequential(
    (0): Conv2d(200, 50, kernel_size=(1, 1), stride=(1, 1))
    (1): LeakyReLU(negative_slope=0.05, inplace=True)
  )
  (LR_conv): Conv2d(50, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (upsampler): Sequential(
    (0): Conv2d(50, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=4)
  )
)
[Epoch 0]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0897]	64.9+3.4s
[3200/16000]	[L1: 0.0679]	61.7+0.2s
[4800/16000]	[L1: 0.0586]	61.2+0.0s
[6400/16000]	[L1: 0.0532]	61.3+0.1s
[8000/16000]	[L1: 0.0496]	61.2+0.1s
[9600/16000]	[L1: 0.0471]	61.4+0.1s
[11200/16000]	[L1: 0.0451]	61.3+0.2s
[12800/16000]	[L1: 0.0437]	61.3+0.2s
[14400/16000]	[L1: 0.0423]	61.2+0.1s
[16000/16000]	[L1: 0.0414]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 29.097 (Best: 29.097 @epoch 1)
Forward: 5.24s

Saving...
Total: 5.80s

[Epoch 1]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0320]	61.5+3.7s
[3200/16000]	[L1: 0.0313]	62.1+0.2s
[4800/16000]	[L1: 0.0314]	61.3+0.1s
[6400/16000]	[L1: 0.0316]	61.2+0.0s
[8000/16000]	[L1: 0.0315]	61.3+0.1s
[9600/16000]	[L1: 0.0314]	61.4+0.2s
[11200/16000]	[L1: 0.0314]	61.0+0.2s
[12800/16000]	[L1: 0.0314]	61.2+0.2s
[14400/16000]	[L1: 0.0314]	61.2+0.2s
[16000/16000]	[L1: 0.0313]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 29.276 (Best: 29.276 @epoch 2)
Forward: 4.01s

Saving...
Total: 4.35s

[Epoch 2]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0300]	61.2+3.2s
[3200/16000]	[L1: 0.0304]	61.0+0.2s
[4800/16000]	[L1: 0.0303]	61.1+0.2s
[6400/16000]	[L1: 0.0303]	60.9+0.2s
[8000/16000]	[L1: 0.0304]	60.9+0.2s
[9600/16000]	[L1: 0.0302]	61.1+0.2s
[11200/16000]	[L1: 0.0302]	62.0+0.2s
[12800/16000]	[L1: 0.0301]	61.8+0.2s
[14400/16000]	[L1: 0.0301]	61.9+0.2s
[16000/16000]	[L1: 0.0300]	62.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 30.041 (Best: 30.041 @epoch 3)
Forward: 5.68s

Saving...
Total: 6.10s

[Epoch 3]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0290]	62.4+3.5s
[3200/16000]	[L1: 0.0287]	62.0+0.2s
[4800/16000]	[L1: 0.0289]	61.9+0.2s
[6400/16000]	[L1: 0.0291]	62.3+0.2s
[8000/16000]	[L1: 0.0292]	62.2+0.2s
[9600/16000]	[L1: 0.0291]	62.1+0.4s
[11200/16000]	[L1: 0.0290]	62.7+0.2s
[12800/16000]	[L1: 0.0289]	61.8+0.2s
[14400/16000]	[L1: 0.0291]	61.8+0.2s
[16000/16000]	[L1: 0.0291]	62.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 30.451 (Best: 30.451 @epoch 4)
Forward: 5.14s

Saving...
Total: 5.58s

[Epoch 4]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0284]	61.9+3.6s
[3200/16000]	[L1: 0.0287]	61.6+0.2s
[4800/16000]	[L1: 0.0288]	61.3+0.2s
[6400/16000]	[L1: 0.0286]	61.0+0.2s
[8000/16000]	[L1: 0.0285]	63.0+0.3s
[9600/16000]	[L1: 0.0288]	63.4+0.3s
[11200/16000]	[L1: 0.0288]	64.4+0.3s
[12800/16000]	[L1: 0.0286]	64.3+0.3s
[14400/16000]	[L1: 0.0287]	64.3+0.2s
[16000/16000]	[L1: 0.0287]	63.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 30.790 (Best: 30.790 @epoch 5)
Forward: 5.93s

Saving...
Total: 6.67s

[Epoch 5]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0274]	64.6+4.3s
[3200/16000]	[L1: 0.0280]	62.4+0.2s
[4800/16000]	[L1: 0.0280]	62.0+0.2s
[6400/16000]	[L1: 0.0279]	61.7+0.2s
[8000/16000]	[L1: 0.0280]	61.9+0.2s
[9600/16000]	[L1: 0.0280]	62.0+0.2s
[11200/16000]	[L1: 0.0279]	62.0+0.2s
[12800/16000]	[L1: 0.0279]	61.8+0.2s
[14400/16000]	[L1: 0.0278]	61.9+0.2s
[16000/16000]	[L1: 0.0277]	62.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 30.843 (Best: 30.843 @epoch 6)
Forward: 5.43s

Saving...
Total: 5.82s

[Epoch 6]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0291]	62.1+3.7s
[3200/16000]	[L1: 0.0286]	62.2+0.2s
[4800/16000]	[L1: 0.0284]	61.8+0.2s
[6400/16000]	[L1: 0.0285]	62.1+0.2s
[8000/16000]	[L1: 0.0282]	61.7+0.2s
[9600/16000]	[L1: 0.0281]	61.1+0.2s
[11200/16000]	[L1: 0.0280]	60.9+0.2s
[12800/16000]	[L1: 0.0280]	61.1+0.2s
[14400/16000]	[L1: 0.0278]	60.9+0.2s
[16000/16000]	[L1: 0.0276]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.109 (Best: 31.109 @epoch 7)
Forward: 4.05s

Saving...
Total: 4.39s

[Epoch 7]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0274]	61.2+3.0s
[3200/16000]	[L1: 0.0276]	61.0+0.2s
[4800/16000]	[L1: 0.0277]	61.0+0.2s
[6400/16000]	[L1: 0.0277]	61.0+0.2s
[8000/16000]	[L1: 0.0275]	61.1+0.2s
[9600/16000]	[L1: 0.0275]	61.1+0.2s
[11200/16000]	[L1: 0.0275]	61.4+0.2s
[12800/16000]	[L1: 0.0275]	61.1+0.2s
[14400/16000]	[L1: 0.0274]	61.0+0.2s
[16000/16000]	[L1: 0.0275]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.239 (Best: 31.239 @epoch 8)
Forward: 4.99s

Saving...
Total: 5.44s

[Epoch 8]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0275]	61.1+3.1s
[3200/16000]	[L1: 0.0272]	61.1+0.2s
[4800/16000]	[L1: 0.0271]	60.9+0.2s
[6400/16000]	[L1: 0.0273]	61.2+0.2s
[8000/16000]	[L1: 0.0274]	61.0+0.2s
[9600/16000]	[L1: 0.0272]	61.0+0.2s
[11200/16000]	[L1: 0.0272]	61.2+0.2s
[12800/16000]	[L1: 0.0273]	61.1+0.2s
[14400/16000]	[L1: 0.0273]	61.3+0.2s
[16000/16000]	[L1: 0.0274]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.200 (Best: 31.239 @epoch 8)
Forward: 3.89s

Saving...
Total: 4.20s

[Epoch 9]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0278]	61.3+2.9s
[3200/16000]	[L1: 0.0271]	61.1+0.2s
[4800/16000]	[L1: 0.0272]	61.2+0.2s
[6400/16000]	[L1: 0.0272]	61.1+0.2s
[8000/16000]	[L1: 0.0271]	61.2+0.2s
[9600/16000]	[L1: 0.0270]	60.9+0.2s
[11200/16000]	[L1: 0.0270]	61.1+0.2s
[12800/16000]	[L1: 0.0270]	61.0+0.2s
[14400/16000]	[L1: 0.0270]	61.0+0.3s
[16000/16000]	[L1: 0.0271]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.319 (Best: 31.319 @epoch 10)
Forward: 4.04s

Saving...
Total: 4.47s

[Epoch 10]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0266]	61.2+3.5s
[3200/16000]	[L1: 0.0267]	61.2+0.2s
[4800/16000]	[L1: 0.0267]	61.4+0.2s
[6400/16000]	[L1: 0.0266]	61.2+0.2s
[8000/16000]	[L1: 0.0269]	61.1+0.2s
[9600/16000]	[L1: 0.0270]	61.0+0.2s
[11200/16000]	[L1: 0.0270]	60.9+0.2s
[12800/16000]	[L1: 0.0269]	61.1+0.2s
[14400/16000]	[L1: 0.0269]	61.0+0.2s
[16000/16000]	[L1: 0.0268]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.325 (Best: 31.325 @epoch 11)
Forward: 4.29s

Saving...
Total: 4.76s

[Epoch 11]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0273]	61.2+3.3s
[3200/16000]	[L1: 0.0269]	60.9+0.2s
[4800/16000]	[L1: 0.0269]	61.1+0.2s
[6400/16000]	[L1: 0.0269]	60.9+0.2s
[8000/16000]	[L1: 0.0270]	60.9+0.2s
[9600/16000]	[L1: 0.0271]	61.3+0.2s
[11200/16000]	[L1: 0.0271]	61.0+0.2s
[12800/16000]	[L1: 0.0271]	60.9+0.2s
[14400/16000]	[L1: 0.0270]	61.0+0.2s
[16000/16000]	[L1: 0.0269]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.427 (Best: 31.427 @epoch 12)
Forward: 3.99s

Saving...
Total: 4.39s

[Epoch 12]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0260]	61.2+2.9s
[3200/16000]	[L1: 0.0267]	61.0+0.2s
[4800/16000]	[L1: 0.0266]	61.0+0.2s
[6400/16000]	[L1: 0.0266]	60.9+0.2s
[8000/16000]	[L1: 0.0264]	61.1+0.2s
[9600/16000]	[L1: 0.0265]	61.0+0.2s
[11200/16000]	[L1: 0.0265]	61.0+0.2s
[12800/16000]	[L1: 0.0265]	61.0+0.2s
[14400/16000]	[L1: 0.0265]	61.2+0.2s
[16000/16000]	[L1: 0.0266]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.497 (Best: 31.497 @epoch 13)
Forward: 3.84s

Saving...
Total: 4.17s

[Epoch 13]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0262]	61.3+2.9s
[3200/16000]	[L1: 0.0269]	61.2+0.2s
[4800/16000]	[L1: 0.0271]	61.0+0.2s
[6400/16000]	[L1: 0.0270]	61.1+0.2s
[8000/16000]	[L1: 0.0270]	60.9+0.2s
[9600/16000]	[L1: 0.0269]	61.1+0.2s
[11200/16000]	[L1: 0.0268]	61.1+0.2s
[12800/16000]	[L1: 0.0268]	61.0+0.2s
[14400/16000]	[L1: 0.0268]	60.9+0.2s
[16000/16000]	[L1: 0.0267]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.547 (Best: 31.547 @epoch 14)
Forward: 4.12s

Saving...
Total: 4.62s

[Epoch 14]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0258]	61.3+3.5s
[3200/16000]	[L1: 0.0260]	60.9+0.2s
[4800/16000]	[L1: 0.0260]	61.1+0.2s
[6400/16000]	[L1: 0.0263]	61.1+0.2s
[8000/16000]	[L1: 0.0264]	61.1+0.2s
[9600/16000]	[L1: 0.0264]	61.1+0.2s
[11200/16000]	[L1: 0.0264]	61.4+0.2s
[12800/16000]	[L1: 0.0265]	61.0+0.2s
[14400/16000]	[L1: 0.0265]	61.1+0.2s
[16000/16000]	[L1: 0.0265]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.486 (Best: 31.547 @epoch 14)
Forward: 3.74s

Saving...
Total: 4.04s

[Epoch 15]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0255]	61.1+2.9s
[3200/16000]	[L1: 0.0262]	61.0+0.2s
[4800/16000]	[L1: 0.0264]	61.0+0.2s
[6400/16000]	[L1: 0.0263]	60.9+0.2s
[8000/16000]	[L1: 0.0264]	61.0+0.2s
[9600/16000]	[L1: 0.0265]	61.0+0.2s
[11200/16000]	[L1: 0.0265]	60.9+0.2s
[12800/16000]	[L1: 0.0266]	61.1+0.2s
[14400/16000]	[L1: 0.0265]	61.0+0.2s
[16000/16000]	[L1: 0.0266]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.566 (Best: 31.566 @epoch 16)
Forward: 3.82s

Saving...
Total: 4.16s

[Epoch 16]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0265]	61.8+2.9s
[3200/16000]	[L1: 0.0265]	61.0+0.2s
[4800/16000]	[L1: 0.0263]	60.9+0.2s
[6400/16000]	[L1: 0.0266]	61.2+0.2s
[8000/16000]	[L1: 0.0265]	60.9+0.2s
[9600/16000]	[L1: 0.0265]	61.1+0.2s
[11200/16000]	[L1: 0.0264]	61.0+0.2s
[12800/16000]	[L1: 0.0265]	61.1+0.2s
[14400/16000]	[L1: 0.0265]	61.0+0.2s
[16000/16000]	[L1: 0.0264]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.547 (Best: 31.566 @epoch 16)
Forward: 4.82s

Saving...
Total: 5.22s

[Epoch 17]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0261]	61.3+3.1s
[3200/16000]	[L1: 0.0267]	61.1+0.2s
[4800/16000]	[L1: 0.0263]	61.1+0.2s
[6400/16000]	[L1: 0.0263]	61.0+0.2s
[8000/16000]	[L1: 0.0263]	61.1+0.2s
[9600/16000]	[L1: 0.0262]	61.1+0.3s
[11200/16000]	[L1: 0.0263]	61.1+0.2s
[12800/16000]	[L1: 0.0263]	61.1+0.2s
[14400/16000]	[L1: 0.0264]	61.1+0.2s
[16000/16000]	[L1: 0.0264]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.612 (Best: 31.612 @epoch 18)
Forward: 3.82s

Saving...
Total: 4.16s

[Epoch 18]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0272]	61.2+3.1s
[3200/16000]	[L1: 0.0265]	61.0+0.2s
[4800/16000]	[L1: 0.0264]	61.1+0.2s
[6400/16000]	[L1: 0.0265]	60.9+0.2s
[8000/16000]	[L1: 0.0263]	61.3+0.2s
[9600/16000]	[L1: 0.0264]	61.0+0.2s
[11200/16000]	[L1: 0.0263]	61.2+0.2s
[12800/16000]	[L1: 0.0263]	61.1+0.2s
[14400/16000]	[L1: 0.0264]	61.1+0.3s
[16000/16000]	[L1: 0.0263]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.634 (Best: 31.634 @epoch 19)
Forward: 3.80s

Saving...
Total: 4.21s

[Epoch 19]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0258]	61.2+3.0s
[3200/16000]	[L1: 0.0265]	61.2+0.2s
[4800/16000]	[L1: 0.0265]	61.0+0.2s
[6400/16000]	[L1: 0.0265]	61.1+0.2s
[8000/16000]	[L1: 0.0261]	61.1+0.2s
[9600/16000]	[L1: 0.0262]	61.1+0.2s
[11200/16000]	[L1: 0.0264]	61.1+0.2s
[12800/16000]	[L1: 0.0264]	61.1+0.2s
[14400/16000]	[L1: 0.0263]	61.0+0.2s
[16000/16000]	[L1: 0.0263]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.693 (Best: 31.693 @epoch 20)
Forward: 4.26s

Saving...
Total: 4.61s

[Epoch 20]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0262]	61.2+3.0s
[3200/16000]	[L1: 0.0258]	60.9+0.2s
[4800/16000]	[L1: 0.0259]	61.0+0.2s
[6400/16000]	[L1: 0.0262]	61.0+0.2s
[8000/16000]	[L1: 0.0261]	61.0+0.2s
[9600/16000]	[L1: 0.0260]	61.1+0.2s
[11200/16000]	[L1: 0.0259]	61.0+0.2s
[12800/16000]	[L1: 0.0260]	61.0+0.2s
[14400/16000]	[L1: 0.0259]	61.0+0.2s
[16000/16000]	[L1: 0.0259]	61.3+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.536 (Best: 31.693 @epoch 20)
Forward: 4.12s

Saving...
Total: 4.48s

[Epoch 21]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0259]	61.3+3.0s
[3200/16000]	[L1: 0.0253]	61.1+0.2s
[4800/16000]	[L1: 0.0258]	61.2+0.2s
[6400/16000]	[L1: 0.0261]	60.9+0.2s
[8000/16000]	[L1: 0.0261]	61.0+0.2s
[9600/16000]	[L1: 0.0261]	61.0+0.2s
[11200/16000]	[L1: 0.0261]	61.0+0.2s
[12800/16000]	[L1: 0.0261]	61.0+0.2s
[14400/16000]	[L1: 0.0261]	61.3+0.2s
[16000/16000]	[L1: 0.0260]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.702 (Best: 31.702 @epoch 22)
Forward: 3.83s

Saving...
Total: 4.14s

[Epoch 22]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0251]	61.1+2.9s
[3200/16000]	[L1: 0.0259]	61.0+0.2s
[4800/16000]	[L1: 0.0260]	61.0+0.2s
[6400/16000]	[L1: 0.0260]	61.1+0.2s
[8000/16000]	[L1: 0.0258]	61.0+0.2s
[9600/16000]	[L1: 0.0258]	61.1+0.2s
[11200/16000]	[L1: 0.0259]	61.0+0.2s
[12800/16000]	[L1: 0.0259]	61.0+0.2s
[14400/16000]	[L1: 0.0260]	61.0+0.2s
[16000/16000]	[L1: 0.0259]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.734 (Best: 31.734 @epoch 23)
Forward: 4.30s

Saving...
Total: 4.62s

[Epoch 23]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0264]	61.1+2.9s
[3200/16000]	[L1: 0.0264]	61.1+0.2s
[4800/16000]	[L1: 0.0265]	61.1+0.2s
[6400/16000]	[L1: 0.0262]	61.2+0.2s
[8000/16000]	[L1: 0.0261]	60.9+0.2s
[9600/16000]	[L1: 0.0262]	61.1+0.2s
[11200/16000]	[L1: 0.0263]	61.0+0.2s
[12800/16000]	[L1: 0.0263]	61.0+0.2s
[14400/16000]	[L1: 0.0263]	61.0+0.2s
[16000/16000]	[L1: 0.0262]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.728 (Best: 31.734 @epoch 23)
Forward: 4.28s

Saving...
Total: 4.58s

[Epoch 24]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0262]	61.4+2.9s
[3200/16000]	[L1: 0.0256]	61.0+0.2s
[4800/16000]	[L1: 0.0256]	61.2+0.2s
[6400/16000]	[L1: 0.0255]	61.2+0.2s
[8000/16000]	[L1: 0.0256]	61.2+0.2s
[9600/16000]	[L1: 0.0257]	60.9+0.2s
[11200/16000]	[L1: 0.0256]	61.0+0.2s
[12800/16000]	[L1: 0.0257]	61.0+0.2s
[14400/16000]	[L1: 0.0256]	61.3+0.2s
[16000/16000]	[L1: 0.0257]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.665 (Best: 31.734 @epoch 23)
Forward: 3.81s

Saving...
Total: 4.10s

[Epoch 25]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0266]	61.3+2.9s
[3200/16000]	[L1: 0.0266]	60.9+0.3s
[4800/16000]	[L1: 0.0263]	61.1+0.3s
[6400/16000]	[L1: 0.0261]	61.0+0.2s
[8000/16000]	[L1: 0.0260]	60.9+0.2s
[9600/16000]	[L1: 0.0260]	61.1+0.2s
[11200/16000]	[L1: 0.0261]	61.1+0.2s
[12800/16000]	[L1: 0.0262]	60.9+0.2s
[14400/16000]	[L1: 0.0261]	61.1+0.2s
[16000/16000]	[L1: 0.0260]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.673 (Best: 31.734 @epoch 23)
Forward: 4.37s

Saving...
Total: 4.72s

[Epoch 26]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0268]	61.3+3.4s
[3200/16000]	[L1: 0.0262]	60.9+0.2s
[4800/16000]	[L1: 0.0259]	61.1+0.2s
[6400/16000]	[L1: 0.0261]	61.0+0.2s
[8000/16000]	[L1: 0.0261]	61.0+0.2s
[9600/16000]	[L1: 0.0260]	61.1+0.2s
[11200/16000]	[L1: 0.0260]	61.0+0.2s
[12800/16000]	[L1: 0.0260]	60.9+0.2s
[14400/16000]	[L1: 0.0260]	61.1+0.2s
[16000/16000]	[L1: 0.0259]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.713 (Best: 31.734 @epoch 23)
Forward: 3.97s

Saving...
Total: 4.32s

[Epoch 27]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0258]	61.3+2.9s
[3200/16000]	[L1: 0.0254]	61.1+0.2s
[4800/16000]	[L1: 0.0254]	61.2+0.2s
[6400/16000]	[L1: 0.0255]	61.2+0.2s
[8000/16000]	[L1: 0.0256]	61.0+0.2s
[9600/16000]	[L1: 0.0255]	61.2+0.2s
[11200/16000]	[L1: 0.0256]	61.4+0.2s
[12800/16000]	[L1: 0.0257]	61.2+0.2s
[14400/16000]	[L1: 0.0258]	61.1+0.2s
[16000/16000]	[L1: 0.0259]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.808 (Best: 31.808 @epoch 28)
Forward: 4.45s

Saving...
Total: 4.93s

[Epoch 28]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0256]	61.3+3.0s
[3200/16000]	[L1: 0.0257]	61.1+0.2s
[4800/16000]	[L1: 0.0258]	61.1+0.2s
[6400/16000]	[L1: 0.0258]	61.0+0.2s
[8000/16000]	[L1: 0.0259]	61.0+0.2s
[9600/16000]	[L1: 0.0259]	61.1+0.3s
[11200/16000]	[L1: 0.0259]	61.1+0.2s
[12800/16000]	[L1: 0.0258]	61.0+0.2s
[14400/16000]	[L1: 0.0258]	61.0+0.2s
[16000/16000]	[L1: 0.0259]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.788 (Best: 31.808 @epoch 28)
Forward: 4.11s

Saving...
Total: 4.42s

[Epoch 29]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0256]	61.3+3.0s
[3200/16000]	[L1: 0.0262]	61.0+0.2s
[4800/16000]	[L1: 0.0260]	61.0+0.2s
[6400/16000]	[L1: 0.0260]	61.1+0.2s
[8000/16000]	[L1: 0.0259]	61.1+0.2s
[9600/16000]	[L1: 0.0259]	60.9+0.2s
[11200/16000]	[L1: 0.0258]	61.0+0.2s
[12800/16000]	[L1: 0.0257]	61.1+0.2s
[14400/16000]	[L1: 0.0257]	61.2+0.2s
[16000/16000]	[L1: 0.0257]	61.3+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.805 (Best: 31.808 @epoch 28)
Forward: 3.94s

Saving...
Total: 4.24s

[Epoch 30]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0258]	61.3+3.2s
[3200/16000]	[L1: 0.0255]	61.1+0.2s
[4800/16000]	[L1: 0.0260]	61.1+0.2s
[6400/16000]	[L1: 0.0262]	61.2+0.2s
[8000/16000]	[L1: 0.0261]	61.0+0.2s
[9600/16000]	[L1: 0.0260]	61.0+0.2s
[11200/16000]	[L1: 0.0260]	61.1+0.2s
[12800/16000]	[L1: 0.0259]	60.9+0.2s
[14400/16000]	[L1: 0.0258]	61.0+0.2s
[16000/16000]	[L1: 0.0259]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.806 (Best: 31.808 @epoch 28)
Forward: 4.13s

Saving...
Total: 4.44s

[Epoch 31]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0267]	61.4+2.9s
[3200/16000]	[L1: 0.0260]	61.1+0.2s
[4800/16000]	[L1: 0.0257]	61.0+0.2s
[6400/16000]	[L1: 0.0254]	61.1+0.2s
[8000/16000]	[L1: 0.0256]	61.1+0.3s
[9600/16000]	[L1: 0.0255]	61.1+0.2s
[11200/16000]	[L1: 0.0255]	61.0+0.3s
[12800/16000]	[L1: 0.0256]	61.1+0.2s
[14400/16000]	[L1: 0.0256]	61.0+0.2s
[16000/16000]	[L1: 0.0256]	61.1+0.3s

Evaluation:
[Set5 x4]	PSNR: 31.819 (Best: 31.819 @epoch 32)
Forward: 4.56s

Saving...
Total: 4.92s

[Epoch 32]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0265]	61.5+3.1s
[3200/16000]	[L1: 0.0264]	61.0+0.2s
[4800/16000]	[L1: 0.0263]	61.0+0.2s
[6400/16000]	[L1: 0.0260]	61.1+0.2s
[8000/16000]	[L1: 0.0260]	61.0+0.2s
[9600/16000]	[L1: 0.0259]	61.2+0.2s
[11200/16000]	[L1: 0.0258]	61.0+0.2s
[12800/16000]	[L1: 0.0259]	61.1+0.2s
[14400/16000]	[L1: 0.0259]	61.0+0.2s
[16000/16000]	[L1: 0.0258]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.730 (Best: 31.819 @epoch 32)
Forward: 3.89s

Saving...
Total: 4.20s

[Epoch 33]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0261]	61.3+3.0s
[3200/16000]	[L1: 0.0259]	61.2+0.2s
[4800/16000]	[L1: 0.0257]	61.3+0.2s
[6400/16000]	[L1: 0.0257]	60.9+0.2s
[8000/16000]	[L1: 0.0256]	61.0+0.2s
[9600/16000]	[L1: 0.0257]	61.1+0.2s
[11200/16000]	[L1: 0.0256]	61.2+0.2s
[12800/16000]	[L1: 0.0257]	60.9+0.2s
[14400/16000]	[L1: 0.0258]	61.1+0.2s
[16000/16000]	[L1: 0.0258]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.739 (Best: 31.819 @epoch 32)
Forward: 3.78s

Saving...
Total: 4.15s

[Epoch 34]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0256]	61.3+2.9s
[3200/16000]	[L1: 0.0260]	61.0+0.2s
[4800/16000]	[L1: 0.0257]	60.9+0.2s
[6400/16000]	[L1: 0.0259]	61.1+0.2s
[8000/16000]	[L1: 0.0260]	61.1+0.2s
[9600/16000]	[L1: 0.0258]	61.0+0.2s
[11200/16000]	[L1: 0.0257]	61.1+0.2s
[12800/16000]	[L1: 0.0257]	60.9+0.2s
[14400/16000]	[L1: 0.0256]	61.3+0.3s
[16000/16000]	[L1: 0.0257]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.774 (Best: 31.819 @epoch 32)
Forward: 4.41s

Saving...
Total: 4.83s

[Epoch 35]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0255]	61.2+3.4s
[3200/16000]	[L1: 0.0255]	61.0+0.2s
[4800/16000]	[L1: 0.0254]	61.5+0.2s
[6400/16000]	[L1: 0.0256]	61.2+0.2s
[8000/16000]	[L1: 0.0255]	61.1+0.2s
[9600/16000]	[L1: 0.0255]	61.2+0.2s
[11200/16000]	[L1: 0.0254]	61.2+0.2s
[12800/16000]	[L1: 0.0256]	61.3+0.2s
[14400/16000]	[L1: 0.0256]	61.1+0.2s
[16000/16000]	[L1: 0.0257]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.867 (Best: 31.867 @epoch 36)
Forward: 4.11s

Saving...
Total: 4.60s

[Epoch 36]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0259]	61.3+3.0s
[3200/16000]	[L1: 0.0259]	60.9+0.2s
[4800/16000]	[L1: 0.0258]	61.1+0.2s
[6400/16000]	[L1: 0.0258]	61.1+0.2s
[8000/16000]	[L1: 0.0260]	60.9+0.2s
[9600/16000]	[L1: 0.0260]	61.1+0.2s
[11200/16000]	[L1: 0.0258]	61.1+0.2s
[12800/16000]	[L1: 0.0258]	61.0+0.2s
[14400/16000]	[L1: 0.0257]	61.0+0.2s
[16000/16000]	[L1: 0.0257]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.847 (Best: 31.867 @epoch 36)
Forward: 3.74s

Saving...
Total: 4.05s

[Epoch 37]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0259]	61.3+2.9s
[3200/16000]	[L1: 0.0262]	61.0+0.2s
[4800/16000]	[L1: 0.0259]	61.0+0.2s
[6400/16000]	[L1: 0.0256]	60.9+0.2s
[8000/16000]	[L1: 0.0257]	61.0+0.2s
[9600/16000]	[L1: 0.0260]	61.2+0.2s
[11200/16000]	[L1: 0.0259]	61.1+0.3s
[12800/16000]	[L1: 0.0258]	61.0+0.2s
[14400/16000]	[L1: 0.0258]	61.1+0.2s
[16000/16000]	[L1: 0.0258]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.788 (Best: 31.867 @epoch 36)
Forward: 3.89s

Saving...
Total: 4.22s

[Epoch 38]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0260]	61.3+3.0s
[3200/16000]	[L1: 0.0254]	61.1+0.2s
[4800/16000]	[L1: 0.0253]	61.1+0.2s
[6400/16000]	[L1: 0.0253]	61.0+0.2s
[8000/16000]	[L1: 0.0254]	61.3+0.2s
[9600/16000]	[L1: 0.0255]	60.9+0.2s
[11200/16000]	[L1: 0.0256]	61.1+0.2s
[12800/16000]	[L1: 0.0256]	61.0+0.2s
[14400/16000]	[L1: 0.0256]	61.0+0.2s
[16000/16000]	[L1: 0.0257]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.790 (Best: 31.867 @epoch 36)
Forward: 5.10s

Saving...
Total: 5.52s

[Epoch 39]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0264]	61.5+3.6s
[3200/16000]	[L1: 0.0259]	61.0+0.2s
[4800/16000]	[L1: 0.0258]	61.5+0.2s
[6400/16000]	[L1: 0.0256]	61.0+0.2s
[8000/16000]	[L1: 0.0256]	61.0+0.2s
[9600/16000]	[L1: 0.0256]	61.1+0.2s
[11200/16000]	[L1: 0.0256]	60.9+0.2s
[12800/16000]	[L1: 0.0257]	60.9+0.2s
[14400/16000]	[L1: 0.0257]	61.0+0.2s
[16000/16000]	[L1: 0.0257]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.882 (Best: 31.882 @epoch 40)
Forward: 4.05s

Saving...
Total: 4.46s

[Epoch 40]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0260]	61.1+3.2s
[3200/16000]	[L1: 0.0256]	61.1+0.2s
[4800/16000]	[L1: 0.0257]	61.0+0.2s
[6400/16000]	[L1: 0.0258]	61.0+0.2s
[8000/16000]	[L1: 0.0258]	60.9+0.2s
[9600/16000]	[L1: 0.0257]	61.2+0.2s
[11200/16000]	[L1: 0.0258]	61.2+0.2s
[12800/16000]	[L1: 0.0257]	61.0+0.2s
[14400/16000]	[L1: 0.0257]	61.2+0.2s
[16000/16000]	[L1: 0.0257]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.854 (Best: 31.882 @epoch 40)
Forward: 3.86s

Saving...
Total: 4.24s

[Epoch 41]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0263]	61.4+3.0s
[3200/16000]	[L1: 0.0259]	61.3+0.2s
[4800/16000]	[L1: 0.0259]	60.9+0.2s
[6400/16000]	[L1: 0.0258]	61.0+0.2s
[8000/16000]	[L1: 0.0258]	61.1+0.2s
[9600/16000]	[L1: 0.0257]	61.1+0.2s
[11200/16000]	[L1: 0.0256]	60.9+0.2s
[12800/16000]	[L1: 0.0255]	61.0+0.2s
[14400/16000]	[L1: 0.0255]	61.1+0.2s
[16000/16000]	[L1: 0.0255]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.846 (Best: 31.882 @epoch 40)
Forward: 3.81s

Saving...
Total: 4.10s

[Epoch 42]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0241]	61.2+2.9s
[3200/16000]	[L1: 0.0244]	61.1+0.2s
[4800/16000]	[L1: 0.0249]	60.8+0.2s
[6400/16000]	[L1: 0.0251]	61.0+0.2s
[8000/16000]	[L1: 0.0253]	61.2+0.2s
[9600/16000]	[L1: 0.0254]	60.9+0.2s
[11200/16000]	[L1: 0.0253]	61.0+0.2s
[12800/16000]	[L1: 0.0255]	61.1+0.2s
[14400/16000]	[L1: 0.0255]	61.2+0.2s
[16000/16000]	[L1: 0.0256]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.868 (Best: 31.882 @epoch 40)
Forward: 4.15s

Saving...
Total: 4.45s

[Epoch 43]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0246]	61.2+2.9s
[3200/16000]	[L1: 0.0252]	60.9+0.2s
[4800/16000]	[L1: 0.0253]	61.1+0.2s
[6400/16000]	[L1: 0.0254]	61.0+0.2s
[8000/16000]	[L1: 0.0254]	61.1+0.2s
[9600/16000]	[L1: 0.0255]	61.1+0.2s
[11200/16000]	[L1: 0.0255]	61.0+0.2s
[12800/16000]	[L1: 0.0256]	61.3+0.2s
[14400/16000]	[L1: 0.0256]	61.0+0.2s
[16000/16000]	[L1: 0.0256]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.848 (Best: 31.882 @epoch 40)
Forward: 4.06s

Saving...
Total: 4.57s

[Epoch 44]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0254]	60.9+3.9s
[3200/16000]	[L1: 0.0252]	61.0+0.3s
[4800/16000]	[L1: 0.0256]	60.9+0.2s
[6400/16000]	[L1: 0.0255]	60.9+0.2s
[8000/16000]	[L1: 0.0254]	61.0+0.2s
[9600/16000]	[L1: 0.0254]	60.9+0.2s
[11200/16000]	[L1: 0.0255]	61.2+0.2s
[12800/16000]	[L1: 0.0254]	60.8+0.2s
[14400/16000]	[L1: 0.0255]	61.0+0.2s
[16000/16000]	[L1: 0.0255]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.809 (Best: 31.882 @epoch 40)
Forward: 3.80s

Saving...
Total: 4.08s

[Epoch 45]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0254]	61.6+2.9s
[3200/16000]	[L1: 0.0255]	61.0+0.2s
[4800/16000]	[L1: 0.0257]	61.0+0.2s
[6400/16000]	[L1: 0.0256]	61.0+0.2s
[8000/16000]	[L1: 0.0258]	61.1+0.2s
[9600/16000]	[L1: 0.0257]	61.0+0.2s
[11200/16000]	[L1: 0.0257]	60.9+0.2s
[12800/16000]	[L1: 0.0257]	60.9+0.2s
[14400/16000]	[L1: 0.0257]	61.1+0.2s
[16000/16000]	[L1: 0.0256]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.840 (Best: 31.882 @epoch 40)
Forward: 3.93s

Saving...
Total: 4.22s

[Epoch 46]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0262]	61.2+3.0s
[3200/16000]	[L1: 0.0256]	61.1+0.2s
[4800/16000]	[L1: 0.0258]	60.9+0.2s
[6400/16000]	[L1: 0.0259]	61.1+0.2s
[8000/16000]	[L1: 0.0259]	61.1+0.2s
[9600/16000]	[L1: 0.0258]	61.2+0.2s
[11200/16000]	[L1: 0.0258]	61.0+0.2s
[12800/16000]	[L1: 0.0257]	61.0+0.2s
[14400/16000]	[L1: 0.0257]	61.1+0.2s
[16000/16000]	[L1: 0.0257]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.847 (Best: 31.882 @epoch 40)
Forward: 4.14s

Saving...
Total: 4.44s

[Epoch 47]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0263]	61.3+3.2s
[3200/16000]	[L1: 0.0254]	61.1+0.2s
[4800/16000]	[L1: 0.0253]	60.9+0.2s
[6400/16000]	[L1: 0.0255]	61.0+0.2s
[8000/16000]	[L1: 0.0251]	61.0+0.2s
[9600/16000]	[L1: 0.0252]	61.2+0.2s
[11200/16000]	[L1: 0.0252]	61.1+0.2s
[12800/16000]	[L1: 0.0252]	61.1+0.2s
[14400/16000]	[L1: 0.0253]	60.9+0.2s
[16000/16000]	[L1: 0.0253]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.899 (Best: 31.899 @epoch 48)
Forward: 3.81s

Saving...
Total: 4.20s

[Epoch 48]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0261]	61.1+3.4s
[3200/16000]	[L1: 0.0258]	61.0+0.2s
[4800/16000]	[L1: 0.0258]	61.1+0.2s
[6400/16000]	[L1: 0.0260]	61.1+0.2s
[8000/16000]	[L1: 0.0258]	61.1+0.2s
[9600/16000]	[L1: 0.0256]	61.0+0.2s
[11200/16000]	[L1: 0.0255]	60.9+0.2s
[12800/16000]	[L1: 0.0255]	61.0+0.2s
[14400/16000]	[L1: 0.0256]	61.1+0.2s
[16000/16000]	[L1: 0.0256]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.885 (Best: 31.899 @epoch 48)
Forward: 3.79s

Saving...
Total: 4.08s

[Epoch 49]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0259]	61.2+2.9s
[3200/16000]	[L1: 0.0256]	60.9+0.2s
[4800/16000]	[L1: 0.0258]	61.0+0.2s
[6400/16000]	[L1: 0.0257]	61.2+0.2s
[8000/16000]	[L1: 0.0259]	61.1+0.2s
[9600/16000]	[L1: 0.0258]	61.1+0.2s
[11200/16000]	[L1: 0.0259]	61.0+0.2s
[12800/16000]	[L1: 0.0259]	61.1+0.2s
[14400/16000]	[L1: 0.0259]	60.9+0.2s
[16000/16000]	[L1: 0.0258]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.922 (Best: 31.922 @epoch 50)
Forward: 3.82s

Saving...
Total: 4.15s

[Epoch 50]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0254]	61.2+2.9s
[3200/16000]	[L1: 0.0255]	61.0+0.3s
[4800/16000]	[L1: 0.0253]	61.0+0.2s
[6400/16000]	[L1: 0.0253]	61.2+0.2s
[8000/16000]	[L1: 0.0252]	60.9+0.2s
[9600/16000]	[L1: 0.0253]	60.8+0.2s
[11200/16000]	[L1: 0.0253]	61.2+0.2s
[12800/16000]	[L1: 0.0253]	61.0+0.2s
[14400/16000]	[L1: 0.0253]	61.7+0.2s
[16000/16000]	[L1: 0.0253]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.940 (Best: 31.940 @epoch 51)
Forward: 4.65s

Saving...
Total: 5.06s

[Epoch 51]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0252]	61.0+3.4s
[3200/16000]	[L1: 0.0251]	60.8+0.2s
[4800/16000]	[L1: 0.0253]	61.0+0.2s
[6400/16000]	[L1: 0.0255]	61.1+0.2s
[8000/16000]	[L1: 0.0255]	61.1+0.2s
[9600/16000]	[L1: 0.0254]	60.9+0.2s
[11200/16000]	[L1: 0.0253]	60.9+0.2s
[12800/16000]	[L1: 0.0254]	61.0+0.2s
[14400/16000]	[L1: 0.0255]	61.1+0.2s
[16000/16000]	[L1: 0.0255]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.861 (Best: 31.940 @epoch 51)
Forward: 3.80s

Saving...
Total: 4.11s

[Epoch 52]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0250]	61.2+2.9s
[3200/16000]	[L1: 0.0256]	61.3+0.2s
[4800/16000]	[L1: 0.0255]	61.2+0.2s
[6400/16000]	[L1: 0.0256]	61.0+0.2s
[8000/16000]	[L1: 0.0254]	61.0+0.2s
[9600/16000]	[L1: 0.0254]	61.2+0.2s
[11200/16000]	[L1: 0.0255]	61.1+0.2s
[12800/16000]	[L1: 0.0255]	61.1+0.2s
[14400/16000]	[L1: 0.0254]	61.2+0.2s
[16000/16000]	[L1: 0.0255]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.921 (Best: 31.940 @epoch 51)
Forward: 3.77s

Saving...
Total: 4.08s

[Epoch 53]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0252]	61.4+3.0s
[3200/16000]	[L1: 0.0256]	61.0+0.2s
[4800/16000]	[L1: 0.0253]	60.9+0.2s
[6400/16000]	[L1: 0.0253]	61.4+0.2s
[8000/16000]	[L1: 0.0255]	61.0+0.2s
[9600/16000]	[L1: 0.0255]	61.2+0.3s
[11200/16000]	[L1: 0.0255]	61.0+0.2s
[12800/16000]	[L1: 0.0256]	60.8+0.2s
[14400/16000]	[L1: 0.0255]	61.0+0.2s
[16000/16000]	[L1: 0.0255]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.763 (Best: 31.940 @epoch 51)
Forward: 3.88s

Saving...
Total: 4.18s

[Epoch 54]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0260]	61.2+2.9s
[3200/16000]	[L1: 0.0255]	60.8+0.2s
[4800/16000]	[L1: 0.0253]	61.0+0.2s
[6400/16000]	[L1: 0.0251]	61.0+0.2s
[8000/16000]	[L1: 0.0252]	61.0+0.2s
[9600/16000]	[L1: 0.0252]	61.0+0.2s
[11200/16000]	[L1: 0.0253]	60.9+0.2s
[12800/16000]	[L1: 0.0253]	61.1+0.2s
[14400/16000]	[L1: 0.0252]	61.1+0.2s
[16000/16000]	[L1: 0.0252]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.876 (Best: 31.940 @epoch 51)
Forward: 3.93s

Saving...
Total: 4.24s

[Epoch 55]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0251]	61.3+3.0s
[3200/16000]	[L1: 0.0247]	61.0+0.2s
[4800/16000]	[L1: 0.0250]	61.3+0.2s
[6400/16000]	[L1: 0.0252]	61.1+0.2s
[8000/16000]	[L1: 0.0251]	61.0+0.2s
[9600/16000]	[L1: 0.0252]	61.0+0.2s
[11200/16000]	[L1: 0.0252]	61.1+0.2s
[12800/16000]	[L1: 0.0253]	61.1+0.2s
[14400/16000]	[L1: 0.0254]	61.4+0.2s
[16000/16000]	[L1: 0.0255]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.966 (Best: 31.966 @epoch 56)
Forward: 3.95s

Saving...
Total: 4.35s

[Epoch 56]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0254]	61.2+2.9s
[3200/16000]	[L1: 0.0255]	61.0+0.3s
[4800/16000]	[L1: 0.0254]	61.0+0.2s
[6400/16000]	[L1: 0.0255]	61.2+0.3s
[8000/16000]	[L1: 0.0254]	61.1+0.2s
[9600/16000]	[L1: 0.0255]	60.9+0.2s
[11200/16000]	[L1: 0.0255]	61.5+0.2s
[12800/16000]	[L1: 0.0254]	61.2+0.3s
[14400/16000]	[L1: 0.0254]	61.1+0.2s
[16000/16000]	[L1: 0.0254]	61.3+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.889 (Best: 31.966 @epoch 56)
Forward: 4.03s

Saving...
Total: 4.33s

[Epoch 57]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0256]	61.2+2.9s
[3200/16000]	[L1: 0.0257]	61.1+0.2s
[4800/16000]	[L1: 0.0255]	61.1+0.2s
[6400/16000]	[L1: 0.0255]	61.0+0.2s
[8000/16000]	[L1: 0.0254]	60.8+0.2s
[9600/16000]	[L1: 0.0254]	60.9+0.2s
[11200/16000]	[L1: 0.0255]	61.1+0.2s
[12800/16000]	[L1: 0.0255]	61.0+0.2s
[14400/16000]	[L1: 0.0253]	61.0+0.2s
[16000/16000]	[L1: 0.0253]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.974 (Best: 31.974 @epoch 58)
Forward: 3.84s

Saving...
Total: 4.17s

[Epoch 58]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0259]	61.4+2.9s
[3200/16000]	[L1: 0.0258]	61.1+0.2s
[4800/16000]	[L1: 0.0255]	61.0+0.2s
[6400/16000]	[L1: 0.0256]	61.1+0.2s
[8000/16000]	[L1: 0.0256]	61.1+0.2s
[9600/16000]	[L1: 0.0256]	61.0+0.2s
[11200/16000]	[L1: 0.0257]	60.9+0.2s
[12800/16000]	[L1: 0.0257]	60.9+0.2s
[14400/16000]	[L1: 0.0256]	61.0+0.2s
[16000/16000]	[L1: 0.0255]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.910 (Best: 31.974 @epoch 58)
Forward: 3.95s

Saving...
Total: 4.27s

[Epoch 59]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0257]	61.3+2.9s
[3200/16000]	[L1: 0.0251]	60.9+0.2s
[4800/16000]	[L1: 0.0255]	61.2+0.2s
[6400/16000]	[L1: 0.0253]	60.9+0.2s
[8000/16000]	[L1: 0.0252]	61.2+0.2s
[9600/16000]	[L1: 0.0252]	60.9+0.2s
[11200/16000]	[L1: 0.0252]	61.2+0.2s
[12800/16000]	[L1: 0.0252]	60.8+0.2s
[14400/16000]	[L1: 0.0253]	61.2+0.2s
[16000/16000]	[L1: 0.0253]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.877 (Best: 31.974 @epoch 58)
Forward: 3.94s

Saving...
Total: 4.30s

[Epoch 60]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0246]	61.0+3.5s
[3200/16000]	[L1: 0.0252]	60.9+0.2s
[4800/16000]	[L1: 0.0252]	60.9+0.2s
[6400/16000]	[L1: 0.0254]	61.0+0.2s
[8000/16000]	[L1: 0.0254]	61.0+0.2s
[9600/16000]	[L1: 0.0254]	60.9+0.2s
[11200/16000]	[L1: 0.0254]	60.9+0.2s
[12800/16000]	[L1: 0.0254]	61.2+0.2s
[14400/16000]	[L1: 0.0254]	61.0+0.2s
[16000/16000]	[L1: 0.0254]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.912 (Best: 31.974 @epoch 58)
Forward: 4.36s

Saving...
Total: 4.67s

[Epoch 61]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0263]	61.1+3.1s
[3200/16000]	[L1: 0.0257]	61.3+0.2s
[4800/16000]	[L1: 0.0256]	61.1+0.2s
[6400/16000]	[L1: 0.0257]	61.0+0.2s
[8000/16000]	[L1: 0.0256]	60.9+0.2s
[9600/16000]	[L1: 0.0257]	61.2+0.3s
[11200/16000]	[L1: 0.0256]	61.0+0.2s
[12800/16000]	[L1: 0.0255]	61.1+0.2s
[14400/16000]	[L1: 0.0256]	61.0+0.2s
[16000/16000]	[L1: 0.0255]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.872 (Best: 31.974 @epoch 58)
Forward: 3.94s

Saving...
Total: 4.26s

[Epoch 62]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0259]	61.4+3.0s
[3200/16000]	[L1: 0.0262]	60.9+0.2s
[4800/16000]	[L1: 0.0258]	61.0+0.2s
[6400/16000]	[L1: 0.0258]	61.2+0.2s
[8000/16000]	[L1: 0.0259]	61.3+0.3s
[9600/16000]	[L1: 0.0258]	61.0+0.2s
[11200/16000]	[L1: 0.0258]	61.0+0.2s
[12800/16000]	[L1: 0.0258]	61.0+0.2s
[14400/16000]	[L1: 0.0257]	61.0+0.2s
[16000/16000]	[L1: 0.0256]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.945 (Best: 31.974 @epoch 58)
Forward: 3.73s

Saving...
Total: 4.08s

[Epoch 63]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0254]	61.4+2.9s
[3200/16000]	[L1: 0.0255]	61.1+0.2s
[4800/16000]	[L1: 0.0255]	61.0+0.2s
[6400/16000]	[L1: 0.0257]	61.0+0.2s
[8000/16000]	[L1: 0.0256]	61.0+0.2s
[9600/16000]	[L1: 0.0256]	61.0+0.2s
[11200/16000]	[L1: 0.0255]	60.9+0.2s
[12800/16000]	[L1: 0.0256]	61.0+0.2s
[14400/16000]	[L1: 0.0256]	61.0+0.2s
[16000/16000]	[L1: 0.0255]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.951 (Best: 31.974 @epoch 58)
Forward: 4.14s

Saving...
Total: 4.46s

[Epoch 64]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0258]	61.1+3.2s
[3200/16000]	[L1: 0.0256]	61.0+0.2s
[4800/16000]	[L1: 0.0254]	61.1+0.2s
[6400/16000]	[L1: 0.0252]	61.2+0.2s
[8000/16000]	[L1: 0.0251]	61.2+0.3s
[9600/16000]	[L1: 0.0250]	61.1+0.2s
[11200/16000]	[L1: 0.0251]	61.2+0.2s
[12800/16000]	[L1: 0.0251]	61.0+0.2s
[14400/16000]	[L1: 0.0251]	61.1+0.2s
[16000/16000]	[L1: 0.0251]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.913 (Best: 31.974 @epoch 58)
Forward: 4.30s

Saving...
Total: 4.63s

[Epoch 65]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0249]	61.3+3.2s
[3200/16000]	[L1: 0.0248]	61.1+0.2s
[4800/16000]	[L1: 0.0252]	61.0+0.2s
[6400/16000]	[L1: 0.0253]	61.0+0.2s
[8000/16000]	[L1: 0.0251]	60.9+0.2s
[9600/16000]	[L1: 0.0251]	61.1+0.2s
[11200/16000]	[L1: 0.0250]	61.1+0.2s
[12800/16000]	[L1: 0.0251]	61.1+0.2s
[14400/16000]	[L1: 0.0251]	60.9+0.2s
[16000/16000]	[L1: 0.0252]	61.0+0.3s

Evaluation:
[Set5 x4]	PSNR: 31.980 (Best: 31.980 @epoch 66)
Forward: 3.74s

Saving...
Total: 4.07s

[Epoch 66]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0258]	61.3+2.9s
[3200/16000]	[L1: 0.0259]	61.0+0.2s
[4800/16000]	[L1: 0.0258]	60.9+0.2s
[6400/16000]	[L1: 0.0257]	61.0+0.2s
[8000/16000]	[L1: 0.0255]	60.9+0.2s
[9600/16000]	[L1: 0.0255]	61.0+0.2s
[11200/16000]	[L1: 0.0255]	61.0+0.2s
[12800/16000]	[L1: 0.0255]	60.9+0.2s
[14400/16000]	[L1: 0.0254]	61.1+0.2s
[16000/16000]	[L1: 0.0255]	61.3+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.959 (Best: 31.980 @epoch 66)
Forward: 4.29s

Saving...
Total: 4.61s

[Epoch 67]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0252]	61.3+2.9s
[3200/16000]	[L1: 0.0251]	60.9+0.2s
[4800/16000]	[L1: 0.0252]	61.1+0.3s
[6400/16000]	[L1: 0.0250]	61.0+0.2s
[8000/16000]	[L1: 0.0248]	61.1+0.2s
[9600/16000]	[L1: 0.0249]	61.2+0.2s
[11200/16000]	[L1: 0.0250]	61.0+0.2s
[12800/16000]	[L1: 0.0252]	61.1+0.2s
[14400/16000]	[L1: 0.0252]	61.0+0.2s
[16000/16000]	[L1: 0.0253]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.946 (Best: 31.980 @epoch 66)
Forward: 4.31s

Saving...
Total: 4.74s

[Epoch 68]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0247]	61.3+3.0s
[3200/16000]	[L1: 0.0249]	61.1+0.2s
[4800/16000]	[L1: 0.0252]	61.4+0.2s
[6400/16000]	[L1: 0.0254]	61.0+0.2s
[8000/16000]	[L1: 0.0252]	61.1+0.2s
[9600/16000]	[L1: 0.0252]	61.1+0.2s
[11200/16000]	[L1: 0.0252]	61.1+0.2s
[12800/16000]	[L1: 0.0252]	61.0+0.2s
[14400/16000]	[L1: 0.0252]	61.0+0.3s
[16000/16000]	[L1: 0.0252]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.954 (Best: 31.980 @epoch 66)
Forward: 3.92s

Saving...
Total: 4.33s

[Epoch 69]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0253]	61.2+3.9s
[3200/16000]	[L1: 0.0253]	61.1+0.2s
[4800/16000]	[L1: 0.0255]	61.1+0.2s
[6400/16000]	[L1: 0.0256]	61.1+0.2s
[8000/16000]	[L1: 0.0256]	61.1+0.2s
[9600/16000]	[L1: 0.0256]	61.0+0.2s
[11200/16000]	[L1: 0.0255]	60.9+0.2s
[12800/16000]	[L1: 0.0255]	61.2+0.2s
[14400/16000]	[L1: 0.0255]	61.0+0.2s
[16000/16000]	[L1: 0.0255]	61.0+0.3s

Evaluation:
[Set5 x4]	PSNR: 31.941 (Best: 31.980 @epoch 66)
Forward: 3.78s

Saving...
Total: 4.17s

[Epoch 70]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0253]	61.3+2.9s
[3200/16000]	[L1: 0.0252]	60.9+0.2s
[4800/16000]	[L1: 0.0251]	61.1+0.2s
[6400/16000]	[L1: 0.0250]	61.0+0.2s
[8000/16000]	[L1: 0.0251]	61.0+0.2s
[9600/16000]	[L1: 0.0251]	61.3+0.2s
[11200/16000]	[L1: 0.0252]	60.8+0.2s
[12800/16000]	[L1: 0.0252]	61.1+0.2s
[14400/16000]	[L1: 0.0253]	61.1+0.2s
[16000/16000]	[L1: 0.0252]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.912 (Best: 31.980 @epoch 66)
Forward: 4.02s

Saving...
Total: 4.33s

[Epoch 71]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0258]	61.4+2.9s
[3200/16000]	[L1: 0.0257]	61.2+0.2s
[4800/16000]	[L1: 0.0255]	61.0+0.2s
[6400/16000]	[L1: 0.0254]	61.2+0.2s
[8000/16000]	[L1: 0.0255]	61.0+0.2s
[9600/16000]	[L1: 0.0255]	61.0+0.2s
[11200/16000]	[L1: 0.0254]	61.0+0.2s
[12800/16000]	[L1: 0.0254]	61.0+0.2s
[14400/16000]	[L1: 0.0254]	61.2+0.2s
[16000/16000]	[L1: 0.0254]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.988 (Best: 31.988 @epoch 72)
Forward: 4.12s

Saving...
Total: 4.46s

[Epoch 72]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0250]	61.0+3.4s
[3200/16000]	[L1: 0.0248]	61.1+0.2s
[4800/16000]	[L1: 0.0252]	61.1+0.2s
[6400/16000]	[L1: 0.0254]	61.1+0.2s
[8000/16000]	[L1: 0.0253]	60.9+0.2s
[9600/16000]	[L1: 0.0254]	61.1+0.2s
[11200/16000]	[L1: 0.0253]	61.1+0.2s
[12800/16000]	[L1: 0.0253]	61.3+0.2s
[14400/16000]	[L1: 0.0253]	61.0+0.2s
[16000/16000]	[L1: 0.0253]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 32.017 (Best: 32.017 @epoch 73)
Forward: 3.96s

Saving...
Total: 4.30s

[Epoch 73]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0250]	61.1+3.8s
[3200/16000]	[L1: 0.0249]	61.1+0.2s
[4800/16000]	[L1: 0.0250]	61.1+0.2s
[6400/16000]	[L1: 0.0248]	61.0+0.2s
[8000/16000]	[L1: 0.0247]	60.9+0.2s
[9600/16000]	[L1: 0.0249]	60.9+0.2s
[11200/16000]	[L1: 0.0251]	61.1+0.2s
[12800/16000]	[L1: 0.0252]	61.0+0.2s
[14400/16000]	[L1: 0.0254]	61.4+0.2s
[16000/16000]	[L1: 0.0254]	61.7+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.943 (Best: 32.017 @epoch 73)
Forward: 4.49s

Saving...
Total: 4.82s

[Epoch 74]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0253]	62.1+3.2s
[3200/16000]	[L1: 0.0250]	61.3+0.2s
[4800/16000]	[L1: 0.0251]	61.0+0.2s
[6400/16000]	[L1: 0.0256]	61.0+0.2s
[8000/16000]	[L1: 0.0255]	61.0+0.2s
[9600/16000]	[L1: 0.0255]	60.9+0.2s
[11200/16000]	[L1: 0.0255]	60.9+0.2s
[12800/16000]	[L1: 0.0253]	60.9+0.2s
[14400/16000]	[L1: 0.0253]	60.9+0.2s
[16000/16000]	[L1: 0.0253]	61.2+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.990 (Best: 32.017 @epoch 73)
Forward: 4.06s

Saving...
Total: 4.37s

[Epoch 75]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0257]	61.3+3.0s
[3200/16000]	[L1: 0.0251]	61.1+0.2s
[4800/16000]	[L1: 0.0251]	61.1+0.2s
[6400/16000]	[L1: 0.0250]	61.1+0.2s
[8000/16000]	[L1: 0.0250]	61.1+0.2s
[9600/16000]	[L1: 0.0251]	61.2+0.2s
[11200/16000]	[L1: 0.0251]	61.1+0.2s
[12800/16000]	[L1: 0.0251]	61.0+0.2s
[14400/16000]	[L1: 0.0251]	61.0+0.2s
[16000/16000]	[L1: 0.0251]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.855 (Best: 32.017 @epoch 73)
Forward: 4.60s

Saving...
Total: 4.94s

[Epoch 76]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0256]	61.0+3.1s
[3200/16000]	[L1: 0.0253]	60.9+0.2s
[4800/16000]	[L1: 0.0254]	60.9+0.2s
[6400/16000]	[L1: 0.0255]	60.9+0.2s
[8000/16000]	[L1: 0.0256]	61.1+0.2s
[9600/16000]	[L1: 0.0257]	61.0+0.2s
[11200/16000]	[L1: 0.0255]	61.2+0.2s
[12800/16000]	[L1: 0.0255]	60.9+0.2s
[14400/16000]	[L1: 0.0254]	60.9+0.2s
[16000/16000]	[L1: 0.0254]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.945 (Best: 32.017 @epoch 73)
Forward: 4.08s

Saving...
Total: 4.47s

[Epoch 77]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0249]	61.3+3.3s
[3200/16000]	[L1: 0.0248]	61.0+0.3s
[4800/16000]	[L1: 0.0248]	61.0+0.2s
[6400/16000]	[L1: 0.0251]	61.0+0.2s
[8000/16000]	[L1: 0.0252]	61.3+0.2s
[9600/16000]	[L1: 0.0251]	61.1+0.2s
[11200/16000]	[L1: 0.0251]	61.0+0.2s
[12800/16000]	[L1: 0.0252]	60.9+0.2s
[14400/16000]	[L1: 0.0252]	60.9+0.2s
[16000/16000]	[L1: 0.0251]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.997 (Best: 32.017 @epoch 73)
Forward: 3.99s

Saving...
Total: 4.33s

[Epoch 78]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0248]	61.1+3.5s
[3200/16000]	[L1: 0.0253]	61.2+0.2s
[4800/16000]	[L1: 0.0253]	61.0+0.2s
[6400/16000]	[L1: 0.0252]	61.2+0.2s
[8000/16000]	[L1: 0.0251]	60.9+0.2s
[9600/16000]	[L1: 0.0252]	61.1+0.2s
[11200/16000]	[L1: 0.0251]	61.2+0.2s
[12800/16000]	[L1: 0.0251]	61.0+0.2s
[14400/16000]	[L1: 0.0252]	60.9+0.2s
[16000/16000]	[L1: 0.0251]	61.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.977 (Best: 32.017 @epoch 73)
Forward: 3.86s

Saving...
Total: 4.17s

[Epoch 79]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0259]	61.4+3.0s
[3200/16000]	[L1: 0.0254]	61.0+0.2s
[4800/16000]	[L1: 0.0253]	61.3+0.2s
[6400/16000]	[L1: 0.0254]	61.0+0.2s
[8000/16000]	[L1: 0.0256]	61.1+0.2s
[9600/16000]	[L1: 0.0254]	60.9+0.2s
[11200/16000]	[L1: 0.0253]	61.2+0.2s
[12800/16000]	[L1: 0.0252]	61.0+0.2s
[14400/16000]	[L1: 0.0251]	61.5+0.2s
[16000/16000]	[L1: 0.0251]	61.1+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.959 (Best: 32.017 @epoch 73)
Forward: 4.11s

Saving...
Total: 4.44s

[Epoch 80]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0252]	61.4+3.9s
[3200/16000]	[L1: 0.0251]	61.1+0.1s
[4800/16000]	[L1: 0.0253]	61.1+0.0s
[6400/16000]	[L1: 0.0253]	61.1+0.0s
[8000/16000]	[L1: 0.0252]	61.2+0.1s
[9600/16000]	[L1: 0.0253]	61.2+0.0s
[11200/16000]	[L1: 0.0253]	61.3+0.0s
[12800/16000]	[L1: 0.0254]	61.2+0.1s
[14400/16000]	[L1: 0.0254]	61.1+0.0s
[16000/16000]	[L1: 0.0253]	61.2+0.0s

Evaluation:
[Set5 x4]	PSNR: 31.895 (Best: 32.017 @epoch 73)
Forward: 3.80s

Saving...
Total: 4.11s

[Epoch 81]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0251]	61.4+2.7s
[3200/16000]	[L1: 0.0255]	61.1+0.0s
[4800/16000]	[L1: 0.0255]	61.3+0.0s
[6400/16000]	[L1: 0.0254]	61.2+0.0s
[8000/16000]	[L1: 0.0254]	61.1+0.0s
[9600/16000]	[L1: 0.0253]	61.2+0.1s
[11200/16000]	[L1: 0.0253]	61.1+0.1s
[12800/16000]	[L1: 0.0251]	61.1+0.0s
[14400/16000]	[L1: 0.0251]	61.2+0.0s
[16000/16000]	[L1: 0.0251]	61.1+0.0s

Evaluation:
[Set5 x4]	PSNR: 31.967 (Best: 32.017 @epoch 73)
Forward: 3.86s

Saving...
Total: 4.19s

[Epoch 82]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0250]	61.3+2.9s
[3200/16000]	[L1: 0.0247]	61.2+0.1s
[4800/16000]	[L1: 0.0246]	61.1+0.1s
[6400/16000]	[L1: 0.0248]	61.3+0.0s
[8000/16000]	[L1: 0.0248]	61.1+0.0s
[9600/16000]	[L1: 0.0248]	61.4+0.0s
[11200/16000]	[L1: 0.0248]	61.1+0.0s
[12800/16000]	[L1: 0.0250]	61.1+0.1s
[14400/16000]	[L1: 0.0250]	61.3+0.1s
[16000/16000]	[L1: 0.0250]	61.3+0.0s

Evaluation:
[Set5 x4]	PSNR: 31.865 (Best: 32.017 @epoch 73)
Forward: 3.86s

Saving...
Total: 4.16s

[Epoch 83]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0251]	61.6+2.8s
[3200/16000]	[L1: 0.0252]	61.2+0.0s
[4800/16000]	[L1: 0.0253]	61.2+0.1s
[6400/16000]	[L1: 0.0252]	61.2+0.0s
[8000/16000]	[L1: 0.0254]	61.3+0.0s
[9600/16000]	[L1: 0.0254]	61.1+0.1s
[11200/16000]	[L1: 0.0254]	61.1+0.0s
[12800/16000]	[L1: 0.0255]	61.2+0.0s
[14400/16000]	[L1: 0.0254]	61.2+0.0s
[16000/16000]	[L1: 0.0255]	61.3+0.0s

Evaluation:
[Set5 x4]	PSNR: 31.975 (Best: 32.017 @epoch 73)
Forward: 3.64s

Saving...
Total: 3.97s

[Epoch 84]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0249]	61.4+2.7s
[3200/16000]	[L1: 0.0250]	61.1+0.1s
[4800/16000]	[L1: 0.0250]	61.2+0.1s
[6400/16000]	[L1: 0.0251]	61.2+0.1s
[8000/16000]	[L1: 0.0252]	61.5+0.0s
[9600/16000]	[L1: 0.0252]	61.2+0.1s
[11200/16000]	[L1: 0.0251]	61.3+0.0s
[12800/16000]	[L1: 0.0251]	61.6+0.1s
[14400/16000]	[L1: 0.0251]	61.1+0.2s
[16000/16000]	[L1: 0.0250]	60.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 32.017 (Best: 32.017 @epoch 85)
Forward: 4.25s

Saving...
Total: 4.64s

[Epoch 85]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0262]	61.3+3.0s
[3200/16000]	[L1: 0.0258]	61.4+0.2s
[4800/16000]	[L1: 0.0254]	61.3+0.1s
[6400/16000]	[L1: 0.0255]	61.4+0.0s
[8000/16000]	[L1: 0.0255]	61.7+0.2s
[9600/16000]	[L1: 0.0252]	61.2+0.2s
[11200/16000]	[L1: 0.0252]	61.7+0.2s
[12800/16000]	[L1: 0.0253]	61.3+0.1s
[14400/16000]	[L1: 0.0253]	61.3+0.1s
[16000/16000]	[L1: 0.0253]	61.1+0.1s

Evaluation:
[Set5 x4]	PSNR: 31.989 (Best: 32.017 @epoch 85)
Forward: 4.06s

Saving...
Total: 4.36s

[Epoch 86]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0250]	61.5+2.8s
[3200/16000]	[L1: 0.0254]	61.1+0.1s
[4800/16000]	[L1: 0.0252]	61.4+0.1s
[6400/16000]	[L1: 0.0254]	61.1+0.0s
[8000/16000]	[L1: 0.0253]	61.1+0.2s
[9600/16000]	[L1: 0.0252]	61.4+0.1s
[11200/16000]	[L1: 0.0253]	61.2+0.2s
[12800/16000]	[L1: 0.0252]	61.3+0.2s
[14400/16000]	[L1: 0.0253]	63.0+0.2s
[16000/16000]	[L1: 0.0253]	63.4+0.1s

Evaluation:
[Set5 x4]	PSNR: 31.987 (Best: 32.017 @epoch 85)
Forward: 3.98s

Saving...
Total: 4.36s

[Epoch 87]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0248]	62.2+3.7s
[3200/16000]	[L1: 0.0249]	61.9+0.2s
[4800/16000]	[L1: 0.0251]	62.0+0.1s
[6400/16000]	[L1: 0.0253]	61.2+0.1s
[8000/16000]	[L1: 0.0252]	64.1+0.2s
[9600/16000]	[L1: 0.0251]	65.0+0.3s
[11200/16000]	[L1: 0.0252]	64.7+0.2s
[12800/16000]	[L1: 0.0252]	64.7+0.3s
[14400/16000]	[L1: 0.0252]	64.6+0.3s
[16000/16000]	[L1: 0.0251]	63.4+0.3s

Evaluation:
[Set5 x4]	PSNR: 32.002 (Best: 32.017 @epoch 85)
Forward: 6.18s

Saving...
Total: 6.76s

[Epoch 88]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0248]	63.8+5.6s
[3200/16000]	[L1: 0.0250]	63.4+0.2s
[4800/16000]	[L1: 0.0249]	66.2+0.3s
[6400/16000]	[L1: 0.0250]	65.3+0.3s
[8000/16000]	[L1: 0.0250]	62.4+0.3s
[9600/16000]	[L1: 0.0249]	62.4+0.2s
[11200/16000]	[L1: 0.0251]	63.3+0.3s
[12800/16000]	[L1: 0.0253]	64.2+0.3s
[14400/16000]	[L1: 0.0253]	62.9+0.3s
[16000/16000]	[L1: 0.0253]	63.0+0.2s

Evaluation:
[Set5 x4]	PSNR: 32.040 (Best: 32.040 @epoch 89)
Forward: 5.63s

Saving...
Total: 6.11s

[Epoch 89]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0249]	63.3+4.9s
[3200/16000]	[L1: 0.0252]	63.2+0.3s
[4800/16000]	[L1: 0.0253]	63.7+0.3s
[6400/16000]	[L1: 0.0251]	61.9+0.3s
[8000/16000]	[L1: 0.0252]	61.9+0.3s
[9600/16000]	[L1: 0.0253]	62.2+0.3s
[11200/16000]	[L1: 0.0252]	62.2+0.3s
[12800/16000]	[L1: 0.0252]	61.5+0.1s
[14400/16000]	[L1: 0.0252]	61.6+0.1s
[16000/16000]	[L1: 0.0252]	63.4+0.3s

Evaluation:
[Set5 x4]	PSNR: 32.037 (Best: 32.040 @epoch 89)
Forward: 5.55s

Saving...
Total: 5.98s

[Epoch 90]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0245]	63.1+4.9s
[3200/16000]	[L1: 0.0246]	63.1+0.2s
[4800/16000]	[L1: 0.0247]	62.2+0.2s
[6400/16000]	[L1: 0.0249]	280.4+0.2s
[8000/16000]	[L1: 0.0249]	65.8+0.2s
[9600/16000]	[L1: 0.0250]	65.3+0.2s
[11200/16000]	[L1: 0.0251]	65.4+0.2s
[12800/16000]	[L1: 0.0251]	65.7+0.2s
[14400/16000]	[L1: 0.0252]	65.4+0.2s
[16000/16000]	[L1: 0.0253]	65.8+0.3s

Evaluation:
[Set5 x4]	PSNR: 32.013 (Best: 32.040 @epoch 89)
Forward: 4.86s

Saving...
Total: 5.19s

[Epoch 91]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0259]	65.9+3.3s
[3200/16000]	[L1: 0.0260]	65.4+0.2s
[4800/16000]	[L1: 0.0257]	65.6+0.2s
[6400/16000]	[L1: 0.0256]	65.9+0.3s
[8000/16000]	[L1: 0.0256]	65.6+0.2s
[9600/16000]	[L1: 0.0255]	65.5+0.2s
[11200/16000]	[L1: 0.0255]	65.6+0.1s
[12800/16000]	[L1: 0.0254]	66.7+0.2s
[14400/16000]	[L1: 0.0254]	65.7+0.4s
[16000/16000]	[L1: 0.0254]	65.9+0.2s

Evaluation:
[Set5 x4]	PSNR: 31.987 (Best: 32.040 @epoch 89)
Forward: 4.51s

Saving...
Total: 5.09s

[Epoch 92]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0255]	66.0+3.4s
[3200/16000]	[L1: 0.0253]	65.8+0.2s
[4800/16000]	[L1: 0.0250]	65.7+0.3s
[6400/16000]	[L1: 0.0249]	65.6+0.2s
[8000/16000]	[L1: 0.0250]	65.7+0.2s
[9600/16000]	[L1: 0.0251]	65.7+0.2s
[11200/16000]	[L1: 0.0251]	65.8+0.2s
[12800/16000]	[L1: 0.0251]	65.8+0.2s
[14400/16000]	[L1: 0.0251]	65.9+0.2s
[16000/16000]	[L1: 0.0251]	65.8+0.2s

Evaluation:
[Set5 x4]	PSNR: 32.026 (Best: 32.040 @epoch 89)
Forward: 4.81s

Saving...
Total: 5.19s

[Epoch 93]	Learning rate: 5.00e-4
[1600/16000]	[L1: 0.0254]	66.8+3.9s
[3200/16000]	[L1: 0.0252]	65.9+0.2s
[4800/16000]	[L1: 0.0251]	65.8+0.2s
[6400/16000]	[L1: 0.0251]	65.8+0.2s
